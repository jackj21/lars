---
title: "Least-angle Regression (LARS)"
author: "Group 5 Overfit Noise: Yahya Hussein, Andrew Farabow, Bryan Nguyen, Jack Jiang, Manning Luo, Shelby Neal"
date: "November 24, 2021"
output: 
  revealjs::revealjs_presentation:
    theme: simple
    highlight: espresso
    widescreen: true
    mathjax: default
    centering: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


## History of Lars

- LARS is an algorithm for fitting regressions to high-dimensional data
developed by Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani
- 

## Core Concepts 

```{r, echo = TRUE}
summary(cars)
```

## When and Why Use Lars

### Some other model selection methods

- Forward selection: starts with no variables in the model, and at each step it adds to the model the variable with the most explanatory power, stopping if the explanatory power falls below some threshold. 
  - This is a fast and simple method, but it can also be too greedy: we fully add variables at each step, so correlated predictors don't get much of a chance to be included in the model.
  - Example: Build a model for the deliciousness of a sandwich 
    - Variables: peanut butter and jelly

## When and Why Use Lars

### Some other model section methods

- Forward stagewise regression: tries to remedy the greediness of forward selection by only partially adding variables. Whereas forward selection finds the variable with the most explanatory power and goes all out in adding it to the model, forward stagewise finds the variable with the most explanatory power and updates its weight by only epsilon in the correct direction. 
  - The problem now is that we have to make tons of updates, so forward stagewise can be very inefficient.

## When and Why Use Lars

- LARS: Instead of making tiny hops in the direction of one variable at a time, LARS makes optimally-sized leaps in optimal directions. These directions are chosen to make equal angles/correlations with each of the variables currently in our model.

## When and Why Use Lars

### Advantages of using Lars

1. Computationally as fast as forward selection but may sometimes be more accurate.
2. Numerically very efficient when the number of features is much larger than the number of data instances.
3. It can easily be modified to produce solutions for other estimators.

## Mathematical Theory

- LARS is related to Forward Selection and based off of Forward Stagewise Regression. 
- Forward Selection, also known as "Forward Stepwise Regression," is an ambitious algorithm that creates a model by selecting the predictors most correlated to the response. 
Downsides?


----

part 2

----

## Baby Example 1
```{r}
plot(pressure)
```

## Baby Example 2
```{r error=FALSE, warning=FALSE, echo=TRUE}
head(mtcars)
attach(mtcars)
```
```{r}
library(lars)
car_x <- mtcars[c(2:11),]

# Using lars function on 
car_lars <- lars(car_x, mpg, type="lar", trace=TRUE, normalize=TRUE, intercept=TRUE)
```


## Lars using Crime
```{r}
plot(pressure)
```

## References
1. https://tibshirani.su.domains/ftp/lars.pdf
2. https://ir.library.louisville.edu/cgi/viewcontent.cgi?article=3487&context=etd
3. https://cran.r-project.org/web/packages/lars/lars.pdf

## Wrap Up 

